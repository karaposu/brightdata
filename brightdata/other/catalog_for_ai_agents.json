{
  "amazon": {
    "title": "AmazonScraper",
    "desc": "Ready-made helper around Bright Data\u2019s Amazon datasets. Automatically picks the right dataset-id for every endpoint.\n",
    "endpoints": {
      "products__collect_by_url": {
        "desc": "Scrape one or many Amazon product pages (ASIN detail).",
        "params": {
          "urls": {
            "type": "list[str]",
            "desc": "Product detail-page URLs."
          },
          "zipcodes": {
            "type": "list[str]",
            "desc": "Postal codes aligned with URLs; empty string to skip."
          }
        },
        "returns": {
          "type": "list[dict] | str",
          "desc": "Immediate rows (sync) or snapshot_id (async)."
        },
        "example": "snap = scraper.products__collect_by_url(\n  [\"https://www.amazon.com/dp/B0CRMZHDG8\"], zipcodes=[\"94107\"]\n)"
      },
      "products__discover_by_category_url": {
        "desc": "Collect new ASINs from category/browse URLs.",
        "params": {
          "category_urls": {
            "type": "list[str]",
            "desc": "Browse-node URLs."
          },
          "sorts": {
            "type": "list[str]",
            "desc": "Sort options aligned with URLs."
          },
          "zipcodes": {
            "type": "list[str]",
            "desc": "Postal codes aligned with URLs."
          }
        },
        "returns": {
          "type": "list[dict] | str",
          "desc": "Immediate rows or snapshot_id."
        },
        "raises": {
          "ValueError": {
            "desc": "If the three input lists\u2019 lengths don\u2019t match."
          }
        },
        "example": "snap = scraper.products__discover_by_category_url(\n  [\"https://www.amazon.com/s?i=electronics\"],\n  sorts=[\"Best Sellers\"],\n  zipcodes=[\"94107\"]\n)"
      },
      "products__discover_by_keyword": {
        "desc": "Run an Amazon keyword search and return new product links.",
        "params": {
          "keywords": {
            "type": "list[str]",
            "desc": "Search terms (one job per keyword)."
          }
        },
        "returns": {
          "type": "list[dict] | str",
          "desc": "Immediate rows or snapshot_id."
        },
        "example": "snap = scraper.products__discover_by_keyword([\"laptop\", \"headphones\"])"
      },
      "products_search__collect_by_url": {
        "desc": "Crawl Amazon SERPs across multiple storefronts.",
        "params": {
          "keywords": {
            "type": "list[str]",
            "desc": "Search strings."
          },
          "domains": {
            "type": "list[str]",
            "desc": "Marketplace domains aligned with keywords."
          },
          "pages": {
            "type": "list[int]",
            "desc": "Number of pages per keyword."
          }
        },
        "returns": {
          "type": "list[dict] | str",
          "desc": "Rows (sync) or snapshot_id (async)."
        },
        "raises": {
          "ValueError": {
            "desc": "If keywords, domains, and pages lengths differ."
          }
        },
        "example": "snap = scraper.products_search__collect_by_url(\n  [\"laptop\"], domains=[\"https://www.amazon.com\"], pages=[2]\n)"
      }
    }
  },
  "digikey": {
    "title": "DigikeyScraper",
    "desc": "High-level wrapper around Bright Data\u2019s Digi-Key datasets. A single dataset-id is used for both collect and discover.\n",
    "endpoints": {
      "collect_by_url": {
        "desc": "Scrape specific Digi-Key product pages.",
        "params": {
          "urls": {
            "type": "list[str]",
            "desc": "Full product-detail URLs."
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id; poll until ready to retrieve `list[dict]` rows."
        },
        "example": "snap = scraper.collect_by_url([\n  \"https://www.digikey.com/en/products/detail/STMicroelectronics/STM32F407VGT6/2747117\",\n  \"https://www.digikey.com/en/products/detail/Texas-Instruments/TPS7A4901PWP/8280491\"\n])"
      },
      "discover_by_category": {
        "desc": "Crawl Digi-Key category pages and return links to *new* parts (Bright Data\u2019s `discover_new` semantics).\n",
        "params": {
          "category_urls": {
            "type": "list[str]",
            "desc": "Full category-page URLs."
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id; poll until ready to retrieve `list[dict]` rows."
        },
        "example": "snap = scraper.discover_by_category([\n  \"https://www.digikey.com/en/products/filter/resistors/general-purpose-fixed/04\"\n])"
      }
    }
  },
  "instagram": {
    "title": "InstagramScraper",
    "desc": "High-level client for Bright Data\u2019s Instagram endpoints. Each method returns immediately with a snapshot-id.\n",
    "endpoints": {
      "comments__collect_by_url": {
        "desc": "Retrieve all comments for the given post or reel URLs.",
        "params": {
          "post_urls": {
            "type": "list[str]",
            "desc": "URLs of posts or reels."
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id; poll until ready to get list[dict]."
        },
        "example": "snap = scraper.comments__collect_by_url([\n  \"https://www.instagram.com/p/Cuf4s0MNqNr\"\n])"
      },
      "posts__collect_by_url": {
        "desc": "Scrape individual Instagram posts (images or reels).",
        "params": {
          "urls": {
            "type": "list[str]",
            "desc": "Post URLs starting with /p/ or /reel/."
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id; poll until ready to get list[dict]."
        },
        "example": "snap = scraper.posts__collect_by_url([\n  \"https://www.instagram.com/p/Cuf4s0MNqNr\",\n  \"https://www.instagram.com/reel/Cuvy6JbtyQ6\"\n])"
      },
      "posts__discover_by_url": {
        "desc": "Crawl multiple posts from profile / hashtag / tagged feeds.",
        "params": {
          "queries": {
            "type": "list[dict]",
            "desc": "Each dict forwarded verbatim to Bright Data.  \nKeys:\n  - url (str, required): profile/hashtag/tagged URL  \n  - num_of_posts (int): max posts  \n  - start_date (MM-DD-YYYY)  \n  - end_date (MM-DD-YYYY)  \n  - post_type (\"Post\"|\"Reel\"|\"\")  \n  - posts_to_not_include (list[str]): IDs  \n"
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id; poll until ready to get list[dict]."
        },
        "example": "snap = scraper.posts__discover_by_url([{\n  \"url\":\"https://www.instagram.com/meta/\",\n  \"num_of_posts\":10,\n  \"post_type\":\"Reel\",\n  \"start_date\":\"01-01-2025\",\n  \"end_date\":\"03-01-2025\"\n}])"
      },
      "profiles__collect_by_url": {
        "desc": "Scrape Instagram profile pages (followers, bio, counters).",
        "params": {
          "urls": {
            "type": "list[str]",
            "desc": "Full profile URLs."
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id; poll until ready to get list[dict]."
        },
        "example": "snap = scraper.profiles__collect_by_url([\n  \"https://www.instagram.com/cats_of_world_/\"\n])"
      },
      "reels__discover_by_url": {
        "desc": "Fetch recent reels for multiple accounts.",
        "params": {
          "queries": {
            "type": "list[dict]",
            "desc": "Same structure as discover_posts_by_url, but only reels:\n  - url (str): profile link  \n  - num_of_posts (int)  \n  - start_date (MM-DD-YYYY)  \n  - end_date (MM-DD-YYYY)\n"
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id; poll until ready to get list[dict]."
        },
        "example": "snap = scraper.reels__discover_by_url([{\n  \"url\":\"https://www.instagram.com/espn\",\n  \"num_of_posts\":5,\n  \"start_date\":\"\",\"end_date\":\"\"\n}])"
      },
      "reels__discover_by_url_all_reels": {
        "desc": "Crawl the complete reel history of each account.",
        "params": {
          "queries": {
            "type": "list[dict]",
            "desc": "Same fields as discover_reels_by_url, but retrieves *all* reels.\n  - url (str)  \n  - num_of_posts (int; leave empty for all)  \n  - start_date, end_date (MM-DD-YYYY)\n"
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id; poll until ready to get list[dict]."
        },
        "example": "snap = scraper.reels__discover_by_url_all_reels([{\n  \"url\":\"https://www.instagram.com/billieeilish\",\n  \"num_of_posts\":20\n}])"
      }
    }
  },
  "linkedin": {
    "title": "LinkedInScraper",
    "desc": "Unified LinkedIn scraper \u2013 wraps the people, company and job Bright-Data\ndatasets.  Each method immediately returns a snapshot-id.\n",
    "endpoints": {
      "collect_by_url": {
        "desc": "Auto-detect the LinkedIn entity type for each URL and dispatch\nthem to the proper collect_* method.\n",
        "params": {
          "urls": {
            "type": "list[str]",
            "desc": "People, company or job URLs (mixed allowed)"
          }
        },
        "returns": {
          "type": "dict[str,str]",
          "desc": "Mapping of {'people','company','job'} \u2192 snapshot_id"
        },
        "example": "snap_map = scraper.collect_by_url([\n  \"https://www.linkedin.com/in/enes-kuzucu/\",\n  \"https://www.linkedin.com/company/105448508/\",\n  \"https://www.linkedin.com/jobs/view/4231516747/\"\n])\n",
        "notes": {
          "mapping": "Stored in self._url_buckets for auto.scrape_url support."
        }
      },
      "company_information__collect_by_url": {
        "desc": "Scrape LinkedIn company pages.",
        "params": {
          "urls": {
            "type": "list[str]",
            "desc": "Company page URLs."
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id."
        },
        "example": "snap = scraper.company_information__collect_by_url([\n  \"https://www.linkedin.com/company/bright-data\"\n])"
      },
      "job_listing_information__collect_by_url": {
        "desc": "Scrape individual LinkedIn job-post URLs.",
        "params": {
          "urls": {
            "type": "list[str]",
            "desc": "Job listing URLs."
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id."
        },
        "example": "snap = scraper.job_listing_information__collect_by_url([\n  \"https://www.linkedin.com/jobs/view/4181034038/\"\n])"
      },
      "job_listing_information__discover_by_keyword": {
        "desc": "Discover job listings via keyword / location search.",
        "params": {
          "queries": {
            "type": "list[dict]",
            "desc": "Each dict must match Bright Data\u2019s expected payload, e.g.:\n  {\"location\":\"Paris\",\n   \"keyword\":\"python developer\",\n   \"country\":\"FR\", ...}\n"
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id."
        },
        "example": "snap = scraper.job_listing_information__discover_by_keyword([{\n  \"location\":\"New York\",\n  \"keyword\":\"Data Scientist\",\n  \"country\":\"US\"\n}])"
      },
      "people_profiles__collect_by_url": {
        "desc": "Scrape individual LinkedIn profile pages.",
        "params": {
          "urls": {
            "type": "list[str]",
            "desc": "Profile URLs (e.g. /in/username)."
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id; poll until ready to get list[dict]."
        },
        "example": "snap = scraper.people_profiles__collect_by_url([\n  \"https://www.linkedin.com/in/elad-moshe-05a90413/\"\n])"
      },
      "people_profiles__discover_by_name": {
        "desc": "Discover profile pages by full-name search.",
        "params": {
          "names": {
            "type": "list[str]",
            "desc": "Full names to search."
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id."
        },
        "example": "snap = scraper.people_profiles__discover_by_name([\"Elad Moshe\", \"Aviv Tal\"])"
      }
    }
  },
  "mouser": {
    "title": "MouserScraper",
    "desc": "Ready-made client for Bright Data\u2019s Mouser product pages dataset.\nAll calls run in async mode and return a snapshot-id immediately.\n",
    "endpoints": {
      "collect_by_url": {
        "desc": "Scrape one or more Mouser **product detail pages**.",
        "params": {
          "urls": {
            "type": "list[str]",
            "desc": "Full Mouser product-page URLs."
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id string; poll until ready to retrieve JSON rows."
        },
        "example": "snap = scraper.collect_by_url([\n  \"https://www.mouser.com/ProductDetail/Diodes-Incorporated/DMN4035L-13?qs=EBDBlbfErPxf4bkLM3Jagg%3D%3D\"\n])"
      }
    }
  },
  "reddit": {
    "title": "RedditScraper",
    "desc": "One class that wraps Bright Data\u2019s \u201ccollect / discover posts\u201d and \u201ccollect comments\u201d Reddit datasets.\n",
    "endpoints": {
      "comments__collect_by_url": {
        "desc": "Scrape comment threads or single comments by URL.",
        "params": {
          "queries": {
            "type": "list[dict]",
            "desc": "Allowed keys:\n  url               (required, str)\n  days_back         int\n  load_all_replies  bool\n  comment_limit     int or \"\"\n"
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id"
        },
        "example": "snap = scraper.comments__collect_by_url([\n  {\"url\":\"https://www.reddit.com/r/singularity/comments/1cmoa52/comment/l31pwza/\",\n   \"days_back\":30,\"load_all_replies\":false,\"comment_limit\":5}\n])"
      },
      "posts__collect_by_url": {
        "desc": "Scrape specific Reddit posts or threads by full URL.",
        "params": {
          "post_urls": {
            "type": "list[str]",
            "desc": "Full post URLs."
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id"
        },
        "example": "snap = scraper.posts__collect_by_url([\n  \"https://www.reddit.com/r/battlefield2042/comments/1cmqs1d/...\"\n])"
      },
      "posts__discover_by_keyword": {
        "desc": "Search Reddit for posts matching one or several keywords.",
        "params": {
          "queries": {
            "type": "list[dict]",
            "desc": "Each dict may include:\n  keyword        (required, str)\n  date           \"All time\" | \"Past year\" | ...\n  num_of_posts   int (optional)\n  sort_by        \"Hot\" | \"Top\" | \"New\" | \"Rising\"\n"
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id"
        },
        "example": "snap = scraper.posts__discover_by_keyword([\n  {\"keyword\":\"datascience\",\"date\":\"All time\",\"sort_by\":\"Hot\"}\n])"
      },
      "posts__discover_by_subreddit_url": {
        "desc": "Crawl multiple posts from one or more subreddit URLs.",
        "params": {
          "queries": {
            "type": "list[dict]",
            "desc": "Keys Bright Data accepts:\n  url            (required, str)\n  sort_by        \"Hot\" | \"New\" | \"Rising\" | \"Top\"\n  sort_by_time   \"Today\" | \"Past week\" | \"All Time\" | \"\"\n"
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id"
        },
        "example": "snap = scraper.posts__discover_by_subreddit_url([\n  {\"url\":\"https://www.reddit.com/r/datascience/\",\n   \"sort_by\":\"Rising\",\"sort_by_time\":\"All Time\"}\n])"
      }
    }
  },
  "tiktok": {
    "title": "TikTokScraper",
    "desc": "Unified client for Bright Data\u2019s TikTok endpoints.  All methods\nrun in async mode and immediately return a snapshot-id string.\n",
    "endpoints": {
      "comments__collect_by_url": {
        "desc": "Retrieve comments for specified TikTok post URLs.",
        "params": {
          "post_urls": {
            "type": "list[str]",
            "desc": "Full TikTok post URLs (must contain `/video/`)."
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id \u2013 poll this until ready to fetch results."
        },
        "example": "snap = scraper.comments__collect_by_url([\n  \"https://www.tiktok.com/@heymrcat/video/7216019547806092550\"\n])"
      },
      "posts__collect_by_url": {
        "desc": "Fast-API variant to scrape one or many TikTok post objects.",
        "params": {
          "post_urls": {
            "type": "list[str]",
            "desc": "TikTok post URLs (must contain `/video/`)."
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id \u2013 poll until ready to retrieve post JSON."
        },
        "example": "snap = scraper.posts__collect_by_url([\n  \"https://www.tiktok.com/@user/video/1234567890\"\n])"
      },
      "posts__discover_by_keyword": {
        "desc": "Discover posts by hashtag or keyword.",
        "params": {
          "keywords": {
            "type": "list[str]",
            "desc": "Use \"#tag\" for hashtags or plain text for search."
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id"
        },
        "example": "snap = scraper.posts__discover_by_keyword([\"#funnydogs\", \"dance\"])"
      },
      "posts__discover_by_profile_url": {
        "desc": "Discover posts via profile URL with filters.",
        "params": {
          "queries": {
            "type": "list[dict]",
            "desc": "Each dict may include:\n  - url (str): profile link\n  - num_of_posts (int): 0 for no limit\n  - posts_to_not_include (list[str])\n  - what_to_collect (str): \"Posts\"|\"Reposts\"|\"Posts & Reposts\"\n  - start_date/end_date (\"MM-DD-YYYY\")\n  - post_type: \"Video\"|\"Image\"|\"\" \n  - country: ISO-2 code or empty\n"
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id"
        },
        "example": "snap = scraper.posts__discover_by_profile_url([{\n  \"url\":\"https://www.tiktok.com/@username\",\n  \"num_of_posts\":10,\n  \"what_to_collect\":\"Posts & Reposts\"\n}])"
      },
      "posts__discover_by_url": {
        "desc": "Discover TikTok feed items (discover/channel/music/explore URLs).",
        "params": {
          "queries": {
            "type": "list[dict]",
            "desc": "Each dict must include:\n  - url (str): e.g. \"https://www.tiktok.com/discover/dog\"\n"
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id"
        },
        "example": "snap = scraper.posts__discover_by_url([{\"url\":\"https://www.tiktok.com/discover/dog\"}])"
      },
      "posts_by_profile_fast_api__collect_by_url": {
        "desc": "Fast-API variant to collect the latest posts from profiles.",
        "params": {
          "urls": {
            "type": "list[str]",
            "desc": "Profile URLs, e.g. \"https://www.tiktok.com/@bbc\"."
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id"
        },
        "example": "snap = scraper.posts_by_profile_fast_api__collect_by_url([\n  \"https://www.tiktok.com/@bbc\",\n  \"https://www.tiktok.com/@portalotempo\"\n])"
      },
      "posts_by_search_url_fast_api__collect_by_url": {
        "desc": "Fast-API variant to collect feed items from search URLs.",
        "params": {
          "queries": {
            "type": "list[dict]",
            "desc": "Each dict may include:\n  - url (str): full search URL (with q=\u2026, t=\u2026)\n  - num_of_posts (int, optional)\n  - country (str, optional)\n"
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id"
        },
        "example": "snap = scraper.posts_by_search_url_fast_api__collect_by_url([\n  {\"url\":\"https://www.tiktok.com/search?lang=en&q=cats&t=\u2026\",\"country\":\"\"},\n  {\"url\":\"https://www.tiktok.com/search?lang=en&q=dogs&t=\u2026\",\"num_of_posts\":10,\"country\":\"US\"}\n])"
      },
      "posts_by_url_fast_api__collect_by_url": {
        "desc": "Fast-API variant to collect arbitrary feed items by URL.",
        "params": {
          "urls": {
            "type": "list[str]",
            "desc": "Full TikTok URLs (discover/channel/music/explore)."
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id"
        },
        "example": "snap = scraper.posts_by_url_fast_api__collect_by_url([\n  \"https://www.tiktok.com/discover/dog1\",\n  \"https://www.tiktok.com/channel/anime\",\n  \"https://www.tiktok.com/music/Some-Track-ID\",\n  \"https://www.tiktok.com/explore?lang=en\"\n])"
      },
      "profiles__collect_by_url": {
        "desc": "Scrape TikTok profile metadata (followers, bio, stats).",
        "params": {
          "profile_urls": {
            "type": "list[str]",
            "desc": "Profile URLs, e.g. \"https://www.tiktok.com/@username\"."
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id"
        },
        "example": "snap = scraper.profiles__collect_by_url([\n  \"https://www.tiktok.com/@fofimdmell\"\n])"
      },
      "profiles__discover_by_search_url": {
        "desc": "Discover TikTok profiles from search/explore URLs.",
        "params": {
          "queries": {
            "type": "list[dict]",
            "desc": "Each dict must contain:\n  - search_url: explore or search URL\n  - country: ISO-2 code or empty\n"
          }
        },
        "returns": {
          "type": "str",
          "desc": "snapshot_id"
        },
        "example": "snap = scraper.profiles__discover_by_search_url([\n  {\"search_url\": \"https://www.tiktok.com/explore?lang=en\", \"country\": \"US\"}\n])"
      }
    }
  }
}